{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44616189",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8c7fba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.8.1: Fast Llama patching. Transformers: 4.55.0.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4080 SUPER. Num GPUs = 1. Max memory: 15.992 GB. Platform: Windows.\n",
      "O^O/ \\_/ \\    Torch: 2.7.1+cu128. CUDA: 8.9. CUDA Toolkit: 12.8. Triton: 3.4.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.31.post1. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.8.1 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yo, Python is a great language to start with, bro! Start with the basics - learn what variables are, loops, and functions. The official Python website has some awesome tutorials for beginners. Then, grab a book like 'Python Crash Course' or watch some YouTube videos. Practice is key, so try working on little projects like a calculator or a game. Don't stress too much about being perfect - just have fun with it, dude! You're gonna be coding like a pro in no time!\n"
     ]
    }
   ],
   "source": [
    "# new_script.py\n",
    "from unsloth import FastLanguageModel\n",
    "from unsloth.chat_templates import get_chat_template\n",
    "from transformers import TextStreamer\n",
    "\n",
    "# Load your trained model\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"doublebank/bro-chatbot\",  # Path to your saved model\n",
    "    max_seq_length = 2048,\n",
    "    dtype = None,\n",
    "    load_in_4bit = True,\n",
    ")\n",
    "\n",
    "# Setup for inference\n",
    "tokenizer = get_chat_template(tokenizer, chat_template = \"llama-3.1\")\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "# Chat function\n",
    "def chat_with_bro(message):\n",
    "    messages = [{\"role\": \"user\", \"content\": message}]\n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        messages, tokenize=True, add_generation_prompt=True, return_tensors=\"pt\"\n",
    "    ).to(\"cuda\")\n",
    "    \n",
    "    text_streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
    "    model.generate(input_ids=inputs, streamer=text_streamer, max_new_tokens=128,\n",
    "                   use_cache=True, temperature=0.7, min_p=0.1)\n",
    "\n",
    "# Use it\n",
    "chat_with_bro(\"How do I learn Python?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0242288b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aw man, that's rough, but you're gonna bounce back from this! Interviews are nerve-wracking for everyone, and they're not always perfect. Maybe it just wasn't your day, or maybe they're just still deciding. Either way, you're way more than your interview skills, bro. Put the disappointment aside and look forward to the next opportunity. You got this - you're gonna land something even better, I can feel it!\n"
     ]
    }
   ],
   "source": [
    "chat_with_bro(\"Eh I'm so down. My interview went south, so make doublebank/bro-chat to help me cope with it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27c1344a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aw man, sorry to hear that, dude. Interviews can be tough, but don't let one bad one keep you down. You gotta keep pushing forward, bro - better days are coming!\n"
     ]
    }
   ],
   "source": [
    "chat_with_bro(\"Make your conversation short. Bro, I'm so down. My interview went south real bad.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cc2366",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brofinetune",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
